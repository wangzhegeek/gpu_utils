# CUDA矩阵乘法程序

这是一个使用CUDA实现的大矩阵乘法程序，提供了多种实现方式的性能对比。

## 功能特点

- 支持大规模矩阵乘法计算
- 提供多种实现方式：
  - CPU实现
  - GPU朴素实现
  - GPU共享内存优化实现
  - cuBLAS库实现
- 自动验证计算结果的正确性
- 性能对比和加速比分析

## 编译方法

```bash
make
```

## 运行方法

```bash
# 运行默认大小（1024x1024）的矩阵乘法
./matrix_multiply

# 测试小矩阵（256x256）的性能
./test_small.sh

# 测试不同大小矩阵的性能（512x512, 1024x1024, 2048x2048, 4096x4096）
./test_different_sizes.sh
```

## 修改矩阵大小

默认矩阵大小为1024x1024。如果需要修改矩阵大小，请编辑`matrix_multiply.cu`文件中的`MATRIX_SIZE`宏定义：

```c
#define MATRIX_SIZE 1024  // 可以根据需要调整矩阵大小
```

## 系统要求

- NVIDIA GPU
- CUDA Toolkit 12.4或更高版本
- cuBLAS库

## 性能测试结果

### 256x256矩阵
- CPU计算时间: 0.020236 秒
- GPU朴素实现计算时间: 0.472953 秒（比CPU慢）
- GPU共享内存优化计算时间: 0.000727 秒（比CPU快27.83倍）
- cuBLAS计算时间: 0.054364 秒（比CPU慢）

### 1024x1024矩阵
- CPU计算时间: 3.264041 秒
- GPU朴素实现计算时间: 0.740334 秒（比CPU快4.41倍）
- GPU共享内存优化计算时间: 0.010799 秒（比CPU快302.26倍）
- cuBLAS计算时间: 0.131082 秒（比CPU快24.90倍）

## 性能分析

1. **小矩阵（256x256）**：
   - 对于小矩阵，CPU实现可能比GPU朴素实现更快，这是因为GPU的数据传输开销相对较大。
   - 共享内存优化实现在小矩阵上表现极佳，比cuBLAS快得多。

2. **大矩阵（1024x1024及以上）**：
   - 随着矩阵大小增加，GPU的优势变得明显。
   - 共享内存优化实现在测试中表现最佳，甚至超过了cuBLAS库。
   - GPU朴素实现虽然比CPU快，但远不如共享内存优化实现和cuBLAS库。

3. **实现方式比较**：
   - GPU朴素实现：简单直接，但性能有限。
   - GPU共享内存优化：通过减少全局内存访问，大幅提高性能。
   - cuBLAS库：高度优化的通用库，但在某些特定大小的矩阵上可能不如专门优化的实现。

## 结论

对于矩阵乘法这类计算密集型任务，GPU可以提供显著的性能提升，特别是对于大型矩阵。共享内存优化是提高CUDA程序性能的关键技术之一，在本测试中甚至超过了专业的cuBLAS库。 